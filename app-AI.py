import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta, timezone
from io import StringIO
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(layout="wide", page_title="æ³•äººæ•¸æ“šç°¡åŒ–æ¸¬è©¦")
TW_TZ = timezone(timedelta(hours=8))

st.title("ğŸ”¬ æ³•äººæ•¸æ“šç°¡åŒ–æ¸¬è©¦ (ç„¡éœ€é¡å¤–å¥—ä»¶)")

tab1, tab2 = st.tabs(["ğŸ“ˆ æ³•äººæœŸè²¨", "ğŸ“Š æ³•äººé¸æ“‡æ¬Š"])

with tab1:
    st.markdown("### ğŸ“ˆ æ³•äººæœŸè²¨ - CSV æ ¼å¼æ¸¬è©¦")
    
    if st.button("ğŸ§ª æ¸¬è©¦", key="fut"):
        url = "https://www.taifex.com.tw/cht/3/futDataDown"
        
        # ğŸ”¥ ä¿®æ­£: æŸ¥è©¢æ˜¨å¤©çš„è³‡æ–™
        query_date = (datetime.now(tz=TW_TZ) - timedelta(days=1)).strftime('%Y/%m/%d')
        
        st.write(f"æ—¥æœŸ: {query_date} (æ˜¨å¤©)")
        st.info("ğŸ’¡ æ³•äººè³‡æ–™é€šå¸¸åœ¨éš”å¤©æ‰æ›´æ–°")
        
        payload = {
            'down_type': '1',
            'queryDate': query_date,
            'commodity_id': 'TX'
        }
        
        try:
            res = requests.post(url, data=payload, timeout=10, verify=False)
            
            # å˜—è©¦ä¸åŒç·¨ç¢¼
            for encoding in ['utf-8', 'big5', 'cp950']:
                try:
                    res.encoding = encoding
                    st.info(f"å˜—è©¦ç·¨ç¢¼: {encoding}")
                    st.info(f"å…§å®¹é•·åº¦: {len(res.text)}")
                    
                    # é¡¯ç¤ºåŸå§‹å…§å®¹
                    with st.expander(f"åŸå§‹å…§å®¹ ({encoding})"):
                        st.text(res.text[:1000])
                    
                    # å˜—è©¦è§£æç‚º CSV
                    try:
                        df = pd.read_csv(StringIO(res.text))
                        st.success(f"âœ… CSV è§£ææˆåŠŸ! ç·¨ç¢¼: {encoding}")
                        st.write(f"è¡¨æ ¼å¤§å°: {df.shape}")
                        st.dataframe(df)
                        
                        # æœå°‹æ³•äºº
                        st.markdown("#### æ³•äººè³‡æ–™æœå°‹")
                        found = False
                        for idx, row in df.iterrows():
                            row_str = " ".join([str(x) for x in row.values])
                            if 'å¤–è³‡' in row_str or 'æŠ•ä¿¡' in row_str or 'è‡ªç‡Ÿå•†' in row_str:
                                st.success(f"âœ… Row {idx}: {row_str}")
                                found = True
                        
                        if found:
                            st.success("ğŸ‰ æ‰¾åˆ°æ³•äººè³‡æ–™!")
                        break
                        
                    except Exception as e:
                        st.warning(f"CSV è§£æå¤±æ•— ({encoding}): {str(e)}")
                        
                except Exception as e:
                    st.error(f"ç·¨ç¢¼ {encoding} å¤±æ•—: {str(e)}")
                    
        except Exception as e:
            st.error(f"è«‹æ±‚å¤±æ•—: {str(e)}")

with tab2:
    st.markdown("### ğŸ“Š æ³•äººé¸æ“‡æ¬Š - CSV æ ¼å¼æ¸¬è©¦")
    
    if st.button("ğŸ§ª æ¸¬è©¦", key="opt"):
        url = "https://www.taifex.com.tw/cht/3/callsAndPutsDateDown"
        
        # ğŸ”¥ ä¿®æ­£: æŸ¥è©¢æ˜¨å¤©çš„è³‡æ–™
        query_date = (datetime.now(tz=TW_TZ) - timedelta(days=1)).strftime('%Y/%m/%d')
        
        st.write(f"æ—¥æœŸ: {query_date} (æ˜¨å¤©)")
        st.info("ğŸ’¡ æ³•äººè³‡æ–™é€šå¸¸åœ¨éš”å¤©æ‰æ›´æ–°")
        
        payload = {
            'down_type': '1',
            'queryDate': query_date,
            'commodity_id': 'TXO'
        }
        
        try:
            res = requests.post(url, data=payload, timeout=10, verify=False)
            
            for encoding in ['utf-8', 'big5', 'cp950']:
                try:
                    res.encoding = encoding
                    st.info(f"å˜—è©¦ç·¨ç¢¼: {encoding}")
                    st.info(f"å…§å®¹é•·åº¦: {len(res.text)}")
                    
                    with st.expander(f"åŸå§‹å…§å®¹ ({encoding})"):
                        st.text(res.text[:1000])
                    
                    try:
                        df = pd.read_csv(StringIO(res.text))
                        st.success(f"âœ… CSV è§£ææˆåŠŸ! ç·¨ç¢¼: {encoding}")
                        st.write(f"è¡¨æ ¼å¤§å°: {df.shape}")
                        st.dataframe(df)
                        
                        st.markdown("#### æ³•äººè³‡æ–™æœå°‹")
                        df_filtered = df[df.iloc[:, 0].astype(str).str.contains('è‡ªç‡Ÿå•†|æŠ•ä¿¡|å¤–è³‡', na=False)]
                        
                        if not df_filtered.empty:
                            st.success(f"âœ… æ‰¾åˆ° {len(df_filtered)} ç­†æ³•äººè³‡æ–™")
                            st.dataframe(df_filtered)
                            st.success("ğŸ‰ æ‰¾åˆ°æ³•äººè³‡æ–™!")
                        
                        break
                        
                    except Exception as e:
                        st.warning(f"CSV è§£æå¤±æ•— ({encoding}): {str(e)}")
                        
                except Exception as e:
                    st.error(f"ç·¨ç¢¼ {encoding} å¤±æ•—: {str(e)}")
                    
        except Exception as e:
            st.error(f"è«‹æ±‚å¤±æ•—: {str(e)}")

st.markdown("---")
st.info("""
ğŸ’¡ é€™å€‹ç‰ˆæœ¬åªç”¨åŸºæœ¬å¥—ä»¶,å¦‚æœèƒ½è§£ææˆåŠŸ,å°±ä¸éœ€è¦å®‰è£ beautifulsoup4ã€‚
å¦‚æœå¤±æ•—,è«‹æ›´æ–° requirements.txt åŠ å…¥:
- beautifulsoup4
- lxml
""")
