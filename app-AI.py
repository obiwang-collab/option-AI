import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta, timezone
from io import StringIO
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(layout="wide", page_title="æœŸäº¤æ‰€æ³•äººè³‡æ–™ - å…¨é¢æ¸¬è©¦")
TW_TZ = timezone(timedelta(hours=8))

st.title("ğŸ”¬ æœŸäº¤æ‰€æ³•äººè³‡æ–™ - å…¨é¢æ¸¬è©¦")

st.info("""
æ ¹æ“šæœŸäº¤æ‰€ç¶²ç«™,æ³•äººè³‡æ–™å¯èƒ½åœ¨é€™äº›åœ°æ–¹:
1. ä¸‰å¤§æ³•äººå°æŒ‡æœŸè²¨äº¤æ˜“å£æ•¸ (futDataDown)
2. ä¸‰å¤§æ³•äººé¸æ“‡æ¬Šäº¤æ˜“å£æ•¸ (callsAndPutsDateDown)
3. æœŸè²¨ä¾æ—¥æœŸæŸ¥è©¢ + èº«ä»½åˆ¥ (futContractsDate)
4. ä¸‰å¤§æ³•äººè³‡æ–™ç¨ç«‹é é¢
""")

if st.button("ğŸš€ é–‹å§‹å…¨é¢æ¸¬è©¦"):
    query_date = (datetime.now(tz=TW_TZ) - timedelta(days=1)).strftime('%Y/%m/%d')
    st.write(f"æ¸¬è©¦æ—¥æœŸ: {query_date}")
    
    # æ‰€æœ‰å¯èƒ½çš„é…ç½®
    test_configs = [
        # === æœŸè²¨æ³•äºº ===
        {
            'name': 'æœŸè²¨æ³•äºº #1: futDataDown + down_type=1',
            'url': 'https://www.taifex.com.tw/cht/3/futDataDown',
            'payload': {'down_type': '1', 'queryDate': query_date, 'commodity_id': 'TX'}
        },
        {
            'name': 'æœŸè²¨æ³•äºº #2: futContractsDateDown',
            'url': 'https://www.taifex.com.tw/cht/3/futContractsDateDown',
            'payload': {'down_type': '1', 'queryDate': query_date, 'commodity_id': 'TX'}
        },
        {
            'name': 'æœŸè²¨æ³•äºº #3: futContractsDate + queryType=2',
            'url': 'https://www.taifex.com.tw/cht/3/futContractsDate',
            'payload': {'queryType': '2', 'queryDate': query_date, 'commodity_id': 'TX'}
        },
        {
            'name': 'æœŸè²¨æ³•äºº #4: ä¸‰å¤§æ³•äººæœŸè²¨ (å¯èƒ½æ˜¯ CSV ç›´æ¥ä¸‹è¼‰)',
            'url': 'https://www.taifex.com.tw/file/taifex/Dailydownload/DailydownloadCSV/Daily_' + query_date.replace('/', '') + '.zip',
            'method': 'GET'
        },
        {
            'name': 'æœŸè²¨æ³•äºº #5: futDataDown (ç„¡ commodity_id)',
            'url': 'https://www.taifex.com.tw/cht/3/futDataDown',
            'payload': {'down_type': '1', 'queryDate': query_date}
        },
        
        # === é¸æ“‡æ¬Šæ³•äºº ===
        {
            'name': 'é¸æ“‡æ¬Šæ³•äºº #1: callsAndPutsDateDown + down_type=1',
            'url': 'https://www.taifex.com.tw/cht/3/callsAndPutsDateDown',
            'payload': {'down_type': '1', 'queryDate': query_date, 'commodity_id': 'TXO'}
        },
        {
            'name': 'é¸æ“‡æ¬Šæ³•äºº #2: callsAndPutsDate + queryType=2',
            'url': 'https://www.taifex.com.tw/cht/3/callsAndPutsDate',
            'payload': {'queryType': '2', 'queryDate': query_date, 'commodity_id': 'TXO'}
        },
        {
            'name': 'é¸æ“‡æ¬Šæ³•äºº #3: optDataDown',
            'url': 'https://www.taifex.com.tw/cht/3/optDataDown',
            'payload': {'down_type': '1', 'queryDate': query_date, 'commodity_id': 'TXO'}
        },
        {
            'name': 'é¸æ“‡æ¬Šæ³•äºº #4: callsAndPutsDateDown (ç„¡ commodity_id)',
            'url': 'https://www.taifex.com.tw/cht/3/callsAndPutsDateDown',
            'payload': {'down_type': '1', 'queryDate': query_date}
        }
    ]
    
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    success_configs = []
    
    for idx, config in enumerate(test_configs, 1):
        st.markdown(f"## æ¸¬è©¦ {idx}/{len(test_configs)}: {config['name']}")
        
        with st.expander("é…ç½®è©³æƒ…", expanded=False):
            st.json(config)
        
        try:
            # ç™¼é€è«‹æ±‚
            if config.get('method') == 'GET':
                res = requests.get(config['url'], headers=headers, timeout=10, verify=False)
            else:
                res = requests.post(config['url'], data=config.get('payload', {}), 
                                  headers=headers, timeout=10, verify=False)
            
            st.info(f"ğŸ“Š ç‹€æ…‹ç¢¼: {res.status_code} | é•·åº¦: {len(res.text)} å­—å…ƒ")
            
            # æª¢æŸ¥éŒ¯èª¤
            if "æ—¥æœŸæ™‚é–“éŒ¯èª¤" in res.text or "DateTime error" in res.text:
                st.warning("âš ï¸ æ—¥æœŸæ™‚é–“éŒ¯èª¤")
                continue
            
            if "æŸ¥ç„¡è³‡æ–™" in res.text:
                st.warning("âš ï¸ æŸ¥ç„¡è³‡æ–™")
                continue
            
            if len(res.text) < 100:
                st.warning("âš ï¸ å›æ‡‰éçŸ­")
                with st.expander("æŸ¥çœ‹å…§å®¹"):
                    st.text(res.text)
                continue
            
            # å˜—è©¦è§£æ
            parsed = False
            
            # 1. å˜—è©¦ CSV
            try:
                for encoding in ['utf-8', 'big5', 'cp950']:
                    try:
                        res.encoding = encoding
                        df = pd.read_csv(StringIO(res.text))
                        
                        if df.shape[0] > 0:
                            st.success(f"âœ… CSV è§£ææˆåŠŸ! (ç·¨ç¢¼: {encoding})")
                            st.write(f"**è¡¨æ ¼å¤§å°:** {df.shape}")
                            st.dataframe(df.head(20))
                            
                            # æœå°‹æ³•äºº
                            has_institutional = False
                            for _, row in df.iterrows():
                                row_str = " ".join([str(x) for x in row.values])
                                if 'å¤–è³‡' in row_str or 'æŠ•ä¿¡' in row_str or 'è‡ªç‡Ÿå•†' in row_str:
                                    has_institutional = True
                                    st.success(f"âœ… æ‰¾åˆ°æ³•äººè³‡æ–™!")
                                    break
                            
                            if has_institutional:
                                st.success("ğŸ‰ğŸ‰ğŸ‰ é€™å€‹é…ç½®æœ‰æ•ˆ!")
                                success_configs.append(config)
                            
                            parsed = True
                            break
                    except:
                        continue
            except:
                pass
            
            # 2. å˜—è©¦ HTML
            if not parsed:
                try:
                    dfs = pd.read_html(StringIO(res.text))
                    if dfs and len(dfs) > 0:
                        st.success(f"âœ… HTML è§£ææˆåŠŸ! æ‰¾åˆ° {len(dfs)} å€‹è¡¨æ ¼")
                        
                        for i, df in enumerate(dfs[:3]):  # åªé¡¯ç¤ºå‰3å€‹è¡¨æ ¼
                            st.write(f"**è¡¨æ ¼ {i+1}:** {df.shape}")
                            st.dataframe(df.head(10))
                            
                            # æœå°‹æ³•äºº
                            for _, row in df.iterrows():
                                row_str = " ".join([str(x) for x in row.values])
                                if 'å¤–è³‡' in row_str or 'æŠ•ä¿¡' in row_str or 'è‡ªç‡Ÿå•†' in row_str:
                                    st.success(f"âœ… æ‰¾åˆ°æ³•äººè³‡æ–™!")
                                    st.success("ğŸ‰ğŸ‰ğŸ‰ é€™å€‹é…ç½®æœ‰æ•ˆ!")
                                    success_configs.append(config)
                                    parsed = True
                                    break
                            
                            if parsed:
                                break
                except:
                    pass
            
            # 3. å¦‚æœéƒ½å¤±æ•—,é¡¯ç¤ºåŸå§‹å…§å®¹
            if not parsed:
                st.warning("âŒ ç„¡æ³•è§£æ")
                with st.expander("æŸ¥çœ‹åŸå§‹å…§å®¹ (å‰1000å­—å…ƒ)"):
                    st.text(res.text[:1000])
            
        except Exception as e:
            st.error(f"âŒ éŒ¯èª¤: {str(e)}")
        
        st.markdown("---")
    
    # ç¸½çµ
    st.markdown("## ğŸ“Š æ¸¬è©¦ç¸½çµ")
    
    if success_configs:
        st.success(f"âœ… æ‰¾åˆ° {len(success_configs)} å€‹æœ‰æ•ˆé…ç½®!")
        
        for config in success_configs:
            st.json(config)
    else:
        st.error("âŒ æ‰€æœ‰é…ç½®éƒ½å¤±æ•—äº†")
        st.info("""
        **å¯èƒ½çš„åŸå› :**
        1. æ³•äººè³‡æ–™ API å·²ç¶“æ”¹è®Š
        2. éœ€è¦ç‰¹æ®Šçš„ token æˆ–èªè­‰
        3. éœ€è¦å¾æœŸäº¤æ‰€é¦–é å…ˆå–å¾— session
        4. è³‡æ–™æ ¼å¼å®Œå…¨ä¸åŒ
        
        **å»ºè­°:**
        è«‹ç›´æ¥åˆ°æœŸäº¤æ‰€ç¶²ç«™æ‰‹å‹•ä¸‹è¼‰æ³•äººè³‡æ–™,çœ‹çœ‹å¯¦éš›çš„ä¸‹è¼‰ URL æ˜¯ä»€éº¼ã€‚
        """)

st.markdown("---")
st.info("""
ğŸ’¡ **å¦‚ä½•æ‰¾åˆ°æ­£ç¢ºçš„ URL:**
1. æ‰“é–‹æœŸäº¤æ‰€ç¶²ç«™
2. æ‰¾åˆ°ä¸‰å¤§æ³•äººè³‡æ–™é é¢
3. æŒ‰ F12 æ‰“é–‹é–‹ç™¼è€…å·¥å…·
4. é»æ“Šä¸‹è¼‰æˆ–æŸ¥è©¢æŒ‰éˆ•
5. åœ¨ Network åˆ†é æŸ¥çœ‹å¯¦éš›çš„è«‹æ±‚ URL å’Œåƒæ•¸
""")
